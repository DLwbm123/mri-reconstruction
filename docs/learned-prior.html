<!DOCTYPE html>
<html>
<meta charset="utf-8">
  <head>
    <title>MRI Reconstruction</title>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        "HTML-CSS": { fonts: ["TeX"] }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML-full">
    </script>
    <link rel="stylesheet" href="style.css">
  </head>

<body>
  <div>
  <h1>Learned priors</h1>

  Using learned priors for compressed sensing can be formalised as;

  $$
  \begin{align}
  \mathop{\text{argmin}}_x &  \;\; \text{prior}(x) \text{  s.t.  } \parallel f(x) - y \parallel_2 \\
  \mathop{\text{argmin}}_x &  \;\; \text{prior}(x) + \lambda \cdot \parallel f(x) - y \parallel_2  \tag{lagrange multiplier}  \\
  \end{align}
  $$


  So, which tools from DL can be used to learn a prior based on the data?
  VAEs, GANS were explored with RIMs on the queue.
  (<i>Note that VAEs and GANs use ground truth images, but do not exploit the knowledge of the forward process</i>)

  <h2><a href=https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf>GANs</a></h2>

  I explored the properties of a simple 2d GAN. The generator takes a 1D noise
  signal and maps it into a 2D space. The goal is to learn to generate samples
  from P(x). However, the infamous mode-collapse-problem is present.

  This is significant in out setting because if a GAN has dropped modes then
  optimising $P_{gan}(x)$ will push $x$ towards only the modes captured
  by the GAN, which may be at the cost of modes not captured by the GAN.

  <img src="assets/gan_init.png">
  <img src="assets/gan_collapse.png">

  <i>At initialisation, the gradients don't point anywhere useful and
    the generator has been initialised spanning one of the modes.</i>

  <p>Unless the mode collapse problem can be reliably solved,
  GANs do not seem like a good idea. Note: there is a large amount of existing
  prior work here, see <a href=https://github.com/act65/mri-reconstruction/blob/master/reading.md>reading.md</a>.</p>

  <h2><a href=https://arxiv.org/abs/1312.6114>VAEs </a></h2>

  I started with a VAE capable of producing good samples.

  <img src="assets/gen.png">

  Then, to get an estimate of  $P(x)$ I sampled from the posterior and used the
  prior to estimate the probability of those samples.
  $$
  \begin{align}
  h_i &= f(x_i) \tag{encode $x_i$} \\
  \end{align}
  $$

  $$
  \begin{align}
  p(x) &:= \mathbb E_{z \sim p(\cdot | h_i)} \left[ p_{prior}(z) \right] \tag{expected prior prob}\\
  \end{align}
  $$

  In the case where we define the latent space to be a univariate gaussian,
  $ h_i = \mu_i, \sigma_i $ and samples are taken from $ \mathcal N(\mu_i, \sigma_i) $
  and the prior is defined to be $ \mathcal N(0, 1) $. Now that we can measure $p(x)$ we
  can optimise it to improve our reconstructions.

  $$
  \begin{align}
  \hat x &= \mathop{\text{argmax}}_x p(x) \\
  x_{t+1} &= x_t + \eta \frac{\partial p(x)}{\partial x} \tag{gradient ascent}\\
  \end{align}
  $$

  So using this estimate of $P(x) $ we can follow its density estimate
  towards more likely images. Thus filling is any missing information in an
  reconstruction. Let explore how it behaves.

  <img src="assets/opt_px_same.png">
  <img src="assets/same_opt_px_imgs.png">

  Despite and increase in $P(x) $, there is no obvious difference in the images. Similarly, below...

  <img src="assets/p_x.png">
  <img src="assets/init_x.png">

  <i>The $x_i$s at initialisation (initialised as MNIST digits plus noise).</i>

  <img src="assets/finals_x.png">

  <i>The $ x_i $s after 1000 steps of gradient ascent.</i>

  <p>So the general problem seems to be that we can happily optimise P(x)
    (examples below), but an increase in P(x) does not necessarily to give us useful results. Why is this happening?</p>

  <img src="assets/opt_px_graph_low_lr.png">
  <img src="assets/opt_px_low_lr.png">

  <i>Images generated every 100 steps (left to right, top to bottom).</i>

  <img src="assets/opt_px.png">
  <img src="assets/opt_px_img.png">

  <i>Images generated every 100 steps (left to right, top to bottom).</i>

  <p>In hindsight I am unsure the calculation of $p(x)$ makes sense. $f(x)$ is supposed to give
    an approximation to the posterior distribution, $q(z | x)$</p>

  $$
  \begin{align}
  p(x) &= E_{ z\sim p(z \mid x) } \left[ p(z) \right] \tag{from above}\\
  &=  \sum_i p(z_i \mid x_i) p(z_i) \tag{!?} \\
  \end{align}
  $$

  <p><i>(but $h_i$ is a deterministic fn of $x_i$ so we should be able to use that!?)</i></p>

  Instead, we could calculate $p(x_i)$ as
  $$
  \begin{align}
  p(x_i) &= E_{ z\sim p(z) } \left[ p(x_i \mid z) \right]  \tag{likelihood of $x_i$ under our prior}\\
  \end{align}
  $$

  <p><i>(Note, this is pretty much just a parzen window)</i></p>

  Maybe this would work with a richer output distribution, rather than just a univariate gaussian?
  (intuition) problem is that even just adding a single pixel of noise might bring $p(x_i | z)$ down to zero.



  <h2>Parzen windows</h2>

  Approximating a density function is a common goal of generative modeling. But there are some subtelties.
  <img src="assets/generative_modelling_challenges.png">

  Given the tip above, I had a play with parzen windows to see how well they
  can be used to turn a VAE into a density estimate. A parzen window can be defined as;

  $$
  p(x) = \frac{1}{n}\sum_i^n k(x, \hat x_i)
  $$

  So, I used the hidden space of a VAE as the inputs to a parzen window (hoping
  the the latent space would give greater generalisation).

  <img src="assets/latent_space.png">

  So using the equation above we can estimate the probability of data.
  $$
  p(x) = \frac{1}{n}\sum_{i=0}^n k(f(x), f(\hat x_i))
  $$

  <img src="assets/parzen_high_temp.png">

  Cool, we seem to have a nice structured estimate of P(x), with gradient pointing in meaningful directions.

  But, using this parzen window we seem to get equal estiamtes of P(x) for images from MNIST and for generated (white noise) images.

  <img src="assets/p_parzen_fake_real.png">

  Ok, the problem is that the kernels are too wide and are allocating probability to locations further away from the data. Solution, reduce the width of the kernels.

  <img src="assets/parzen_low_temp.png">
  <img src="assets/p_parzen_separated.png">

  The problem is now that the gradients don't point in any meaningful directions. They will simply lead you to the nearest data point.

  <p><i>Maybe there is an optimal tuning of the width to give desired results.
    But I didnt spend much time exploring this.</i></p>

  <h3>Future directions</h3>

  <p>Quick wins: Could try playing with <a href=https://en.wikipedia.org/wiki/Gaussian_process>Gaussian processes</a>
   or <a href=https://arxiv.org/abs/1807.01622>Neural processes</a>.</p>

  <p>The code for RIMs exists in <a href=https://github.com/act65/mri-reconstruction/tree/master/src>src</a>,
    but it will take some more effort to reproduce the papers results.</p>

  <p>There is no reason $\phi(x)$ must be explicitly representing a density.
  Rather, we could learn a sparse representation of the data and use this to
  regularise reconstructions to plausible images.</p>
</div>
</body>
</html>
