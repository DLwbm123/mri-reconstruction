{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed sensing\n",
    "\n",
    "http://statweb.stanford.edu/~candes/papers/StableRecovery.pdf\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\text{Assume $\\forall x_i \\in X$;} \\tag{the true signals}\\\\\n",
    "&\\quad\\text{(1) $x_i \\in \\mathbb R^m$} \\\\\n",
    "&\\quad\\text{(2) $x_i$ is sufficiently sparse} \\\\\n",
    "&\\text{Given $f(x_i) = Ax_i+e$ such that;} \\tag{the function we know}\\\\\n",
    "&\\quad\\text{(2) $A$ is approx orthonormal}\\\\ \n",
    "&\\quad\\text{(3) and $e$ is bounded} \\\\\n",
    "&\\text{Given $y_i = f(x_i)$ such that;} \\tag{the observations}\\\\\n",
    "&\\quad\\text{(2) where $n << m$} \\\\\n",
    "x_i^* &= \\text{min} \\parallel \\tilde x_i\\parallel_1 \\text{subject to} \\parallel f(\\tilde x_i) - y_i \\parallel \\le \\epsilon \\tag{?}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Requirements.\n",
    "- $x_i$ is sufficiently sparse\n",
    "- $A$ is approximatley orthonormal\n",
    "- $e$ is bounded (this was just needed to make the proofs easier?!? otherwise would need measures?)\n",
    "- iid samples!?\n",
    "\n",
    "#### Misunderstanding.\n",
    "\n",
    "I thought we were matching the signals in a sparse basis.\n",
    "We take our signal, $x_i$ and project it into a new basis where the signal has a sparse representation. We then match signals in this basis.\n",
    "\n",
    "Rather the above requires $x_i$ itself to be sparse.\n",
    "\n",
    "Oh, if $A$ is approximately orthonormal then $y_i$ will also be sparse!? No.\n",
    "\n",
    "#### Search\n",
    "\n",
    "Want a simple 2D case. Show how it is underdetermined.\n",
    "> convex program searching, among all signals consistent with the data y\n",
    "\n",
    "\n",
    "#### Structured spaces and regularisers and priors\n",
    "\n",
    "The trick is using structure in the spaces, X/Y, to help us ...?\n",
    "What about other structure in X or Y? How can that be translated into a regulariser?\n",
    "\n",
    "Want to learn the distinct strutures of a space (e.g. smooth, sparse, ...) and then apply them when solving for x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse representations\n",
    "\n",
    "Ok, so can we just learn a sparse representation?\n",
    "Take an AE, use a large hidden space, and regularise it to be sparse!?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Isometry\n",
    "\n",
    "Let $X$ and $Y$ be metric spaces with metrics $d_X$ and $d_Y$. A map $f : X \\to Y$ is called an isometry or distance preserving if for any $a,b \\in X$ one has\n",
    "\n",
    "$$d_Y( f(a), f(b)) = d_X (a, b) $$\n",
    "\n",
    "\n",
    "## Restricted isometry\n",
    "\n",
    "> This property essentially requires that every set of columns with cardinality less than\n",
    "$S$ approximately behaves like an orthonormal system. [source](http://statweb.stanford.edu/~candes/papers/StableRecovery.pdf)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(1-\\delta_S)\\parallel x \\parallel_2^2 \\le \\parallel A_Sx \\parallel \\le (1+\\delta_S)\\parallel x \\parallel_2^2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "I am confused. If $A_{S_N}$ (all the columns) satisfies RIP then shouldnt the other $A_S$?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\parallel A_s^*A_s-I\\parallel_{2\\to 2}\\leq \\delta_s \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "> A challenging aspect of RIP is its computational cost. Indeed, RIP is a property of the submatrices of a specific size. At present, no subexponential-time algorithm is known for testing RIP. [source](https://arxiv.org/pdf/0812.3137.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(n, S):\n",
    "    if S == 1:\n",
    "        return list(itertools.combinations(range(n), 1))\n",
    "    else:\n",
    "        return list(itertools.combinations(range(n), S)) + combinations(n, S-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_orth(A, t):\n",
    "    A_s = A[:, t]\n",
    "    u, s, v = np.linalg.svd(np.dot(A_s.conj().T, A_s))\n",
    "    e_S = np.abs(s - np.ones(len(t)))\n",
    "    return np.max(e_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_matrix(N):\n",
    "    i, j = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    omega = np.exp( - 2 * np.pi * 1J / N )\n",
    "    W = np.power( omega, i * j ) / np.sqrt(N)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rim(A, S):\n",
    "    T = combinations(A.shape[-1], S)\n",
    "    return np.max([approx_orth(A, t) for t in T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0658141036401503e-14,\n",
       " 1.099120794378905e-14,\n",
       " 1.2545520178264269e-14,\n",
       " 1.3433698597964394e-14,\n",
       " 1.3766765505351941e-14,\n",
       " 1.4210854715202004e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14,\n",
       " 1.4432899320127035e-14]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rim(ft_matrix(15), i) for i in range(1, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7082281239704467,\n",
       " 1.1847212362098167,\n",
       " 1.41341056257362,\n",
       " 1.5968500301894166,\n",
       " 1.6782821675460822,\n",
       " 1.7341228419466281,\n",
       " 1.7639518661661806,\n",
       " 1.7694464508204697,\n",
       " 1.7699056758830496]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.standard_normal((10, 10))\n",
    "A /= np.linalg.norm(A, axis=1, keepdims=True)\n",
    "# axis = 0 or 1!?\n",
    "\n",
    "[rim(A, i) for i in range(1, A.shape[-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear RIP\n",
    "\n",
    "Relationship to the gradient!? (and hessian?! where was that reference!?!?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling the data.\n",
    "\n",
    "Can use signals in a sparse basis.\n",
    "Thus the model is many causes/bases -> image.\n",
    "\n",
    "What about other types of model?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
