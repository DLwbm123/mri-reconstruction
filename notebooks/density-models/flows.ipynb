{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tangent as tgt\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should define class Dense(tfb.Bijector): ...\n",
    "def Dense(num_units, name):\n",
    "    with tf.variable_scope('affine_transform' + name) as scope:\n",
    "        shift = tf.get_variable(name='shift', shape=[num_units], dtype=tf.float32)\n",
    "        mat = tf.get_variable(name='scale', shape=[num_units, num_units], dtype=tf.float32)\n",
    "        scale = tf.linalg.LinearOperatorFullMatrix(mat)\n",
    "        affine = tfb.AffineLinearOperator(shift, scale=scale)\n",
    "        return affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 16\n",
    "fn = tfb.Chain([\n",
    "    Dense(num_units, '0'),\n",
    "    Dense(num_units, '1'),\n",
    "])\n",
    "dist = tfd.MultivariateNormalDiag(loc=tf.zeros([num_units]))\n",
    "\n",
    "density = tfd.TransformedDistribution(\n",
    "    distribution=dist,\n",
    "    bijector=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using (possibly slow) default implementation of solve.  Requires conversion to a dense matrix and O(N^3) operations.\n",
      "WARNING:tensorflow:Using (possibly slow) default implementation of solve.  Requires conversion to a dense matrix and O(N^3) operations.\n",
      "WARNING:tensorflow:Using (possibly slow) default implementation of determinant.  Requires conversion to a dense matrix and O(N^3) operations.\n",
      "WARNING:tensorflow:Using (possibly slow) default implementation of determinant.  Requires conversion to a dense matrix and O(N^3) operations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n",
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n",
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n",
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=448, shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.random_normal([10, num_units])\n",
    "density.prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv(num_units, name):\n",
    "    # want a way to impose structural priors on the fn\n",
    "    # to add local/hierarchical prior\n",
    "    # i guess this is what autoregressive flows attempt to do???\n",
    "    \n",
    "    # how can I construct invertible fns that change the dimensionality!?\n",
    "    with tf.variable_scope('conv_transform' + name) as scope:\n",
    "        shift = tf.get_variable(name='shift', shape=[num_units*num_units])\n",
    "        mat = tf.get_variable(name='scale', shape=[num_units, num_units], dtype=tf.float32)\n",
    "        spectrum = tf.fft2d(tf.cast(mat, tf.complex64))\n",
    "        scale = tf.linalg.LinearOperatorCirculant2D(spectrum, input_output_dtype=tf.float32)\n",
    "        affine = tfb.AffineLinearOperator(shift, scale=scale)\n",
    "        return affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Want a hierarchical version of autoregressive flow.\n",
    "    Each layer is generated conditional on the previous one.\n",
    "    P(x) = P(x|z_n)P(z_n|z_n-1) ... P(z_1|z_0)\n",
    "    \n",
    "    It must be possible to construct a conv bijector as no info is destroyed!?\n",
    "    Hmm, maybe not, same with linear operators, but det = 0. need to investigate.\n",
    "    \n",
    "    # TODO want to weaken to approximate inversion!?\n",
    "    # will want guarantees on error\n",
    "    > \" Geometrically, the Jacobian determinant is the volume of the transformation and is used to scale the probability\"\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_outputs, stride, validate_args=False, name='conv'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_inputs (int): the number of features (last dim)\n",
    "            n_outputs (int): the target num of feautres\n",
    "            stride (int): the size of steps to take when convolving\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        If the bijector changes the shape of the input, you must also implement:\n",
    "\n",
    "          - _forward_event_shape_tensor,\n",
    "          - _forward_event_shape (optional),\n",
    "          - _inverse_event_shape_tensor,\n",
    "          - _inverse_event_shape (optional).\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__(\n",
    "            validate_args=validate_args,\n",
    "            forward_min_event_ndims=0,\n",
    "            name=name)\n",
    "        \n",
    "        self.n_outputs = n_outputs\n",
    "        self.stride = stride\n",
    "        self.output_shape = None\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            self.weights = tf.get_variable(name='weights', \n",
    "                                           shape=[4,4,x.shape[-1],n_outputs], \n",
    "                                           dtype=tf.float32)\n",
    "            self.bias = tf.get_variable(name='bias', \n",
    "                                        shape=[n_outputs], \n",
    "                                        dtype=tf.float32)\n",
    "            \n",
    "    def dfdx(self, x, w, b):\n",
    "        # copied from tanget\n",
    "        l = [1, self.stride, self.stride, 1]\n",
    "        b_return = tf.ones(self.output_shape)\n",
    "        \n",
    "        tf_nn_conv2d = tf.nn.conv2d(x, w, l, padding='SAME')\n",
    "        _return = tf_nn_conv2d + b\n",
    "        assert tgt.shapes_match(_return, b_return\n",
    "            ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
    "            numpy.shape(_return), numpy.shape(b_return))\n",
    "\n",
    "        # Grad of: _return = tf_nn_conv2d + b\n",
    "        _btf_nn_conv2d = tgt.unbroadcast(b_return, tf_nn_conv2d)\n",
    "        btf_nn_conv2d = _btf_nn_conv2d\n",
    "\n",
    "        # Grad of: tf_nn_conv2d = tf.nn.conv2d(x, w, l, padding='SAME')\n",
    "        _bx = tf.nn.conv2d_backprop_input(tf.shape(x), w, btf_nn_conv2d, l, 'SAME')\n",
    "        bx = _bx\n",
    "        return bx\n",
    "                \n",
    "    def _forward(self, x):\n",
    "        self.output_shape = tf.shape(x)\n",
    "        return tf.nn.conv2d(x, self.weights, [1,self.stride,self.stride,1], padding='SAME')\n",
    "    \n",
    "    def _inverse(self, y):\n",
    "        # TODO how can I verify this!? x = f_1(f(x))\n",
    "        if self.output_shape is None:\n",
    "            shape = tf.shape(y)\n",
    "            self.output_shape = [shape[0], shape[1]//self.stride, \n",
    "                                  shape[1]//self.stride, self.n_outputs]\n",
    "        return tf.nn.conv2d_transpose(y, self.weights, strides=[1,self.stride,self.stride,1],\n",
    "                                      output_shape=self.output_shape)\n",
    "    \n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        # what shape is this supposed to return!?!!?\n",
    "        \n",
    "        # the det of any low rank linear operator is zero\n",
    "        # but ?!?!? bc we take the det of the weights\n",
    "        J = self.dfdx(x, self.weights, self.bias)\n",
    "        # jacobian of a linear fn should be constant accross all batches.\n",
    "        return tf.log(non_square_det(J))\n",
    "    \n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        return -self._forward_log_det_jacobian(self.inverse(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_square_det(x):\n",
    "    # https://www.quora.com/How-do-we-calculate-the-determinant-of-a-non-square-matrix\n",
    "    \n",
    "    # tests. equal for square mats?\n",
    "    # x = tf.random_normal([3,3])\n",
    "    # non_square_det(x), tf.linalg.det(x)\n",
    "    \n",
    "    if len(x.shape) > 2:\n",
    "        x_ = tf.reshape(x, [x.shape[0], x.shape[1]*x.shape[2], x.shape[3]])\n",
    "        squared_mat = tf.matmul(x_, x_, transpose_b=True)\n",
    "        return tf.sqrt(tf.linalg.det(squared_mat))\n",
    "    else:\n",
    "        squared_mat = tf.matmul(x, x, transpose_b=True)\n",
    "        det = tf.sqrt(tf.linalg.det(squared_mat))\n",
    "        return tf.linalg.det(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=519, shape=(), dtype=float32, numpy=128.04897>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random_normal([10,10])\n",
    "non_square_det(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_normal([10,28,28,4])\n",
    "det = non_square_det(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_normal([2, 28,28,1])\n",
    "f = Conv(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1793, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f.forward(x)\n",
    "x_ = f.inverse(y)  # uses caching!?\n",
    "tf.reduce_sum(x-x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1799, shape=(), dtype=float32, numpy=-1.368999>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ = tfb.Invert(f)  # does this construct a new instance?? which would mean new params are init\n",
    "x_ = f_.forward(y)\n",
    "tf.reduce_sum(x-x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() missing 1 required positional argument: 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-c53479de8a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36mforward_log_det_jacobian\u001b[0;34m(self, x, event_ndims, name)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minjective\u001b[0m \u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \"\"\"\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_forward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36m_call_forward_log_det_jacobian\u001b[0;34m(self, x, event_ndims, name, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Not needed; leave cache as is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m           \u001b[0mildj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m           ildj = self._reduce_jacobian_det_over_event(\n\u001b[1;32m    932\u001b[0m               x, ildj, self.forward_min_event_ndims, event_ndims)\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/invert.py\u001b[0m in \u001b[0;36m_forward_log_det_jacobian\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_forward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-2e96b1e850a2>\u001b[0m in \u001b[0;36m_inverse_log_det_jacobian\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-2e96b1e850a2>\u001b[0m in \u001b[0;36m_forward_log_det_jacobian\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# but ?!?!? bc we take the det of the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_square_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-c330c2f2ac00>\u001b[0m in \u001b[0;36mnon_square_det\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msquared_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reshape() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "f_.forward_log_det_jacobian(x, event_ndims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using (possibly slow) default implementation of determinant.  Requires conversion to a dense matrix and O(N^3) operations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/act65/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/platform/tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([]),\n",
       " <tf.Tensor: id=2050, shape=(), dtype=float32, numpy=2.8675199>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random_normal([2,8])\n",
    "g = tfb.AffineLinearOperator(shift=tf.random_normal([8]),\n",
    "                             scale=tf.linalg.LinearOperatorFullMatrix(tf.random_normal([8,8])))\n",
    "y = g.forward_log_det_jacobian(x, event_ndims=1)\n",
    "y.shape, y  #?!?!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1130, shape=(), dtype=float32, numpy=-inf>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_.inverse_log_det_jacobian(y, event_ndims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = tfb.Chain([\n",
    "    Conv(n_inputs=1, n_outputs=1, stride=1, name='0'),\n",
    "#     tfb.Invert(Conv(n_inputs=1, n_outputs=1, stride=2, name='1')),\n",
    "])\n",
    "dist = tfd.MultivariateNormalDiag(loc=tf.zeros([1, 28, 28, 1]), \n",
    "                                  scale_diag=tf.ones([1, 28, 28, 1]))\n",
    "\n",
    "density = tfd.TransformedDistribution(\n",
    "    distribution=dist,\n",
    "    bijector=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(28), Dimension(28), Dimension(1)])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = density.sample()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Invalid reduction dimension (-1 for input with 0 dimension(s) [Op:Sum]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-d039dcb54474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, value, name)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \"\"\"\n\u001b[0;32m--> 763\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_log_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36m_call_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_prob\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mevent_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_get_static_event_ndims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mildj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_injective\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_prob_for_one_fiber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mildj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36minverse_log_det_jacobian\u001b[0;34m(self, y, event_ndims, name)\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_inverse_log_det_jacobian\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \"\"\"\n\u001b[0;32m--> 885\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_inverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_forward_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36m_call_inverse_log_det_jacobian\u001b[0;34m(self, y, event_ndims, name, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m           \u001b[0mildj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m           ildj = self._reduce_jacobian_det_over_event(\n\u001b[0;32m--> 839\u001b[0;31m               y, ildj, self.inverse_min_event_ndims, event_ndims)\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36m_reduce_jacobian_det_over_event\u001b[0;34m(self, y, ildj, min_event_ndims, event_ndims)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return math_ops.reduce_sum(\n\u001b[1;32m   1017\u001b[0m           \u001b[0mildj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m           self._get_event_reduce_dims(min_event_ndims, event_ndims))\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;31m# In this case, we need to tile the Jacobian over the event and reduce.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1331\u001b[0m                                                   reduction_indices),\n\u001b[1;32m   1332\u001b[0m                                    \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                                    name=name))\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   8344\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8345\u001b[0m       return _sum_eager_fallback(\n\u001b[0;32m-> 8346\u001b[0;31m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8347\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8348\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_sum_eager_fallback\u001b[0;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[1;32m   8366\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8367\u001b[0m   _result = _execute.execute(b\"Sum\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 8368\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   8369\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   8370\u001b[0m       \"Sum\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension (-1 for input with 0 dimension(s) [Op:Sum]"
     ]
    }
   ],
   "source": [
    "p = density.prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=895, shape=(), dtype=float32, numpy=100.00001>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.det(tf.constant([\n",
    "    [100.0, 0.0],\n",
    "    [1e-10, 1.0]\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n |  A `TransformedDistribution` using `MaskedAutoregressiveFlow(...)` uses the\\n |  (expensive) forward-mode calculation to draw samples and the (cheap)\\n |  reverse-mode calculation to compute log-probabilities. Conversely, a\\n |  `TransformedDistribution` using `Invert(MaskedAutoregressiveFlow(...))` uses\\n |  the (expensive) forward-mode calculation to compute log-probabilities and the\\n |  (cheap) reverse-mode calculation to compute samples.  See \"Example Use\"\\n |  [below] for more details.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " |  A `TransformedDistribution` using `MaskedAutoregressiveFlow(...)` uses the\n",
    " |  (expensive) forward-mode calculation to draw samples and the (cheap)\n",
    " |  reverse-mode calculation to compute log-probabilities. Conversely, a\n",
    " |  `TransformedDistribution` using `Invert(MaskedAutoregressiveFlow(...))` uses\n",
    " |  the (expensive) forward-mode calculation to compute log-probabilities and the\n",
    " |  (cheap) reverse-mode calculation to compute samples.  See \"Example Use\"\n",
    " |  [below] for more details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Caching devices are not yet supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-28312c9a2fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     event_shape=[1, dims])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Expensive; uses `tf.while_loop`, no Bijector caching.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Almost free; uses Bijector caching.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cheap; no `tf.while_loop` despite no Bijector caching.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, seed, name)\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0msamples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mprepended\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \"\"\"\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_sample_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_call_sample_n\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m       \u001b[0;31m# work, it is imperative that this is the last modification to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0;31m# returned result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_sample_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, name)\u001b[0m\n\u001b[1;32m    762\u001b[0m       \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bijector_impl.py\u001b[0m in \u001b[0;36m_call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m       \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/masked_autoregressive.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_loop_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         maximum_iterations=static_event_size)\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3208\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3200\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3201\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow_probability/python/bijectors/masked_autoregressive.py\u001b[0m in \u001b[0;36m_loop_body\u001b[0;34m(index, y0)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaching_device\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_caching_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shift_and_log_scale_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mri/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mset_caching_device\u001b[0;34m(self, caching_device)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;34m\"\"\"Set caching_device for this scope.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       raise NotImplementedError(\"Caching devices are not yet supported \"\n\u001b[0m\u001b[1;32m   1116\u001b[0m                                 \"when eager execution is enabled.\")\n\u001b[1;32m   1117\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_caching_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Caching devices are not yet supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "\n",
    "dims = 5\n",
    "# A common choice for a normalizing flow is to use a Gaussian for the base\n",
    "# distribution. (However, any continuous distribution would work.) E.g.,\n",
    "maf = tfd.TransformedDistribution(\n",
    "distribution=tfd.Normal(loc=0., scale=1.),\n",
    "bijector=tfb.MaskedAutoregressiveFlow(\n",
    "    shift_and_log_scale_fn=tfb.masked_autoregressive_default_template(\n",
    "    hidden_layers=[512, 512])),\n",
    "    event_shape=[1, dims])\n",
    "\n",
    "x = maf.sample()  # Expensive; uses `tf.while_loop`, no Bijector caching.\n",
    "maf.log_prob(x)   # Almost free; uses Bijector caching.\n",
    "maf.log_prob(0.)  # Cheap; no `tf.while_loop` despite no Bijector caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
