{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import mri\n",
    "from src import rim\n",
    "from src.utils import PyramidLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "inputs = tf.placeholder(shape=[batch_size, 784], dtype=tf.float32)\n",
    "x = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "x = tf.cast(x, tf.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(50, 28, 28, 1) dtype=complex64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = mri.MRI()\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Recurrent inference machines](https://openreview.net/forum?id=HkSOlP9lg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rim = rim.RIM(f.dLdx, 196)\n",
    "x_t = rim(y)\n",
    "\n",
    "x, x_t = (tf.real(x), tf.real(x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new idea. can introduce a loss at every step, rather than just at\n",
    "# the end. need to test versus loss at end.\n",
    "\n",
    "def summarise_candidates(model):\n",
    "    for i, x_t in enumerate(rim.candidate_xs):\n",
    "        tf.summary.image('x_t/{}'.format(i), tf.real(x_t), max_outputs=1)\n",
    "        \n",
    "def candidate_loss(model, x):\n",
    "    return tf.add_n([tf.losses.mean_squared_error(x, x_t)\n",
    "              for x_t in rim.candidate_xs])\n",
    "        \n",
    "summarise_candidates(rim)\n",
    "loss = candidate_loss(rim, x)\n",
    "tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tf.summary.image('x_t', x_t)\n",
    "# # tf.summary.image('x', x)\n",
    "\n",
    "\n",
    "# loss = tf.losses.mean_squared_error(x, x_t)\n",
    "# # loss_fn = PyramidLoss(32, 3)\n",
    "# # loss = loss_fn((x, x_t))\n",
    "# tf.summary.scalar('loss', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer()\n",
    "train_step = opt.minimize(loss, var_list=rim.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"/tmp/rim/candidate/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5551148653030396"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    idx = np.random.randint(0, len(mnist.train.images), 50)\n",
    "    sess.run(train_step, feed_dict={inputs: mnist.train.images[idx, ...]})\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        L, summary = sess.run([loss, merged], feed_dict={inputs: mnist.test.images[:50, ...]})\n",
    "        writer.add_summary(summary, i)\n",
    "        print('\\rloss: {}'.format(L), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
