## Inverse learning

Given a dataset $\{x_i, y_i: x_i \in X, y_i \in Y\}$ and the forward process $f: X \to Y$ construct an approximation to $f^{-1}: Y \to X$.

Let $X= \mathbb R^{n}$ and $Y=\mathbb R^{m}$ then set $n >> m$. Want to minimize $m$ while maintaining the ability to accurately reconstruct $x_i$.

<!-- So we have control over the forward function...!? -->

Thoughts:

*
* Similar to compressed sensing, but we also have access to;
  - the $x_i$s
  - $df$.


Compressed sensing

$$

$$

Solutions
- learned prior - GAN
- learned sparse basis - AE


## Online sampling





## Reconstruction with context

## ?
